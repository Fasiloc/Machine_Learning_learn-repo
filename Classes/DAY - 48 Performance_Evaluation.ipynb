{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DAY 48 - Performance Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "Lqux0Hh6IrN6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Diabetes.csv')"
      ],
      "metadata": {
        "id": "N_cdhOrFLZqj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Outcome'].value_counts()"
      ],
      "metadata": {
        "id": "HBAOoL7ELiX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['Outcome'], axis=1)\n",
        "y = df['Outcome']"
      ],
      "metadata": {
        "id": "PC3dtmZmMfUT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "h0KRnurTM1T4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = SVC(kernel = 'linear', probability=True)\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "n_mWQwdyNCvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "ZUcnPxA3OmpP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy: %.2f'% accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "0qta0IpkcGT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "qT0gg4_LO65X"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, cmap=\"YlGnBu\")\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('Actual Values')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "krkOVgAZO80g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Precision: %.3f' % precision_score(y_test, y_pred))\n",
        "print('Recall: %.3f' % recall_score(y_test, y_pred))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "ieXO8LsqUeLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting AUC & ROC"
      ],
      "metadata": {
        "id": "mWMX2sSYZlZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probs = clf.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "giLeJo2cNVN8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keep probabilities for the positive outcome only\n",
        "probs = probs[:, 1]"
      ],
      "metadata": {
        "id": "qx7EfR0aN4dg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc = roc_auc_score(y_test, probs)\n",
        "print('AUC - Test Set: %.2f%%' % (auc*100))"
      ],
      "metadata": {
        "id": "KpbmQ2qcODDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.ylabel('True Positive Rate (TPR)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s6z5YVLrOM4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting multiple models"
      ],
      "metadata": {
        "id": "KJ6_FrfTK3uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "fKJ2hWIWK2ns"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the classfiers and make a list\n",
        "classifiers = [LogisticRegression(max_iter=1000), \n",
        "               SVC(kernel = 'linear', probability=True),\n",
        "               GaussianNB(), \n",
        "               KNeighborsClassifier(), \n",
        "               DecisionTreeClassifier(),\n",
        "               RandomForestClassifier()]"
      ],
      "metadata": {
        "id": "LCyXeSYTK_86"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])"
      ],
      "metadata": {
        "id": "ZQGT0wErLTLT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the models and record the results\n",
        "for cls in classifiers:\n",
        "    model = cls.fit(X_train, y_train)\n",
        "    yproba = model.predict_proba(X_test)\n",
        "    yproba = yproba[:, 1]\n",
        "    \n",
        "    fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
        "    auc = roc_auc_score(y_test, yproba)\n",
        "    \n",
        "    result_table = result_table.append({'classifiers':cls.__class__.__name__,\n",
        "                                        'fpr':fpr, \n",
        "                                        'tpr':tpr, \n",
        "                                        'auc':auc}, ignore_index=True)\n",
        "\n",
        "# Set name of the classifiers as index labels\n",
        "result_table.set_index('classifiers', inplace=True)"
      ],
      "metadata": {
        "id": "H-1JJiWMLdYJ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8,6))\n",
        "\n",
        "for i in result_table.index:\n",
        "    plt.plot(result_table.loc[i]['fpr'], \n",
        "             result_table.loc[i]['tpr'], \n",
        "             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n",
        "\n",
        "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
        "plt.legend(prop={'size':13}, loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fdWfFfy8LxBT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}